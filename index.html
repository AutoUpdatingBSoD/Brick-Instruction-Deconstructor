<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.min.js"></script>
<input type="file" id="imageUpload" multiple>
<div id="testlog"></div>
<script>
var testlog = document.getElementById("testlog");
// Ensure WebGPU Backend for TensorFlow.js
async function setupBackend() {
    await tf.setBackend('webgl'); // Enables Vulkan-based GPU acceleration
    console.log(`Using backend: ${tf.getBackend()}`);
}

setupBackend();

// Load image and convert to tensor
async function loadImage(url) {

    return new Promise((resolve) => {
        const img = new Image();
        img.crossOrigin = "anonymous"; // To prevent CORS issues
        img.src = url;
        img.onload = () => resolve(img);
    });
    testlog.innerHTML = testlog.innerHTML + "<br><br>done with loadImage)";
}

// Convert image to TensorFlow.js tensor
async function processImage(img) {
    return tf.browser.fromPixels(img)
        .resizeNearestNeighbor([128, 128]) // Resize to match model input size
        .toFloat()
        .div(tf.scalar(255)) // Normalize pixel values
}
// Convert image to TensorFlow.js tensor
async function processImage2(img) {
    return tf.browser.fromPixels(img)
        .resizeNearestNeighbor([128, 128]) // Resize to match model input size
        .toFloat()
        .div(tf.scalar(255)) // Normalize pixel values
        .expandDims()
}
// Define the CNN Model
const model = tf.sequential();
model.add(tf.layers.conv2d({ inputShape: [128, 128, 3], filters: 32, kernelSize: 3, activation: 'relu' }));
model.add(tf.layers.maxPooling2d({ poolSize: [2, 2] }));
model.add(tf.layers.conv2d({ filters: 64, kernelSize: 3, activation: 'relu' }));
model.add(tf.layers.maxPooling2d({ poolSize: [2, 2] }));
model.add(tf.layers.flatten());
model.add(tf.layers.dense({ units: 128, activation: 'relu' }));
model.add(tf.layers.dense({ units: 10, activation: 'sigmoid' })); // 10 categories (adjust as needed)

model.compile({ optimizer: tf.train.adam(), loss: 'binaryCrossentropy', metrics: ['accuracy'] });

async function loadDataset() {
    const dataset = [];
    const categories = [
        'bagset', 'dontreadrepeat', 'finish', 'index', 'pageno', 
        'part', 'partstep', 'repeat', 'splitdecision', 'subbuild'
    ];
    const indices = [
        5, 2, 2, 4, 4, 
        26, 18, 4, 2, 6
    ];
    const baseDir = 'model/dataset/'; // Path relative to your GitHub-hosted environment

    for (var j = 0; j < categories.length; j++) {
        category = categories[j];
        jth = indices[j];
        for (var i = 1; i <= jth; i++){
            const imageUrl = `${baseDir}${category}/${category} ${i}.png`;

            try {
                const response = await fetch(imageUrl, { method: 'HEAD' });
                if (!response.ok) break; // Stop fetching when file doesn't exist

                dataset.push({
                    path: imageUrl,
                    label: categories.indexOf(category)
                });
            } catch (error) {
                testlog.innerHTML = testlog.innerHTML + "<br><br>error " + category + " " + i;
                break; // Stop when no more files are found
            }
           testlog.innerHTML = testlog.innerHTML + "<br><br>pushed " + category + " " + i;
        }
    }

    const imageTensors = [];
    const labels = [];

    for (const item of dataset) {
        const img = await loadImage(item.path);
        const tensor = await processImage(img);
        imageTensors.push(tensor);
        const labelVector = new Array(categories.length).fill(0);
        if (item.label == 0){
            labelVector[item.label] = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0];            
        }
        if (item.label == 1){
            labelVector[item.label] = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0];            
        }
        if (item.label == 2){
            labelVector[item.label] = [0, 0, 1, 0, 1, 0, 0, 0, 0, 0];            
        }
        if (item.label == 3){
            labelVector[item.label] = [0, 0, 0, 1, 1, 1, 0, 1, 0, 0];            
        }
        if (item.label == 4){
            labelVector[item.label] = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0];            
        }
        if (item.label == 5){
            labelVector[item.label] = [0, 0, 0, 0, 0, 1, 0, 1, 0, 0];            
        }
        if (item.label == 6){
            labelVector[item.label] = [0, 0, 0, 0, 0, 0, 1, 1, 0, 0];            
        }
        if (item.label == 7){
            labelVector[item.label] = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0];            
        }
        if (item.label == 8){
            labelVector[item.label] = [0, 0, 0, 0, 1, 0, 0, 0, 1, 0];            
        }
        if (item.label == 9){
            labelVector[item.label] = [0, 1, 0, 0, 0, 0, 0, 0, 0, 1];            
        }
        labels.push(labelVector);
            testlog.innerHTML = testlog.innerHTML + "<br><br>labeled " + item.label;
    }

    return {
        xs: tf.stack(imageTensors),
        ys: tf.tensor2d(labels) // [num_samples, 10]
    };
}

// Train the model
async function trainModel() {
    const { xs, ys } = await loadDataset();
    testlog.innerHTML = testlog.innerHTML + "<br><br>started training" + xs;
    await model.fit(xs, ys, {
        epochs: 20,
        batchSize: 16,
        validationSplit: 0.2,
        callbacks: tf.callbacks.earlyStopping({ patience: 3 })
    });

        testlog.innerHTML = testlog.innerHTML + "<br><br> Training Complete";
}
async function classifyExtractedImages(pdfUrl) {
    const images = await extractImagesFromPDF(pdfUrl);
    var j = 0;
    for (const imgSrc of images) {
        const img = new Image();
        img.src = imgSrc;

        img.onload = async () => {
           const prediction = model.predict(tensor);
            const predictionData = await prediction.data();
            const threshold = 0.5;

            const predictedCategories = predictionData
                .map((val, idx) => (val > threshold ? idx : -1))
                .filter(idx => idx !== -1);

                predictedCategories.forEach(categoryIndex => {
                testlog.innerHTML += `<br>Detected category: ${categoryIndex}`;
});
        };
    }
}
async function extractImagesFromPDF(pdfUrl) {
    testlog.innerHTML = testlog.innerHTML + "<br><br>Started reading pages ";
    const pdf = await pdfjsLib.getDocument(pdfUrl).promise;
    const numPages = pdf.numPages;
    const extractedImages = [];

    for (let i = 1; i <= numPages; i++) {
                testlog.innerHTML = testlog.innerHTML + "<br><br>Started reading page " + i;
        const page = await pdf.getPage(i);
        const viewport = page.getViewport({ scale: 2.0 });

        // Render the page onto a canvas
        const canvas = document.createElement("canvas");
        const ctx = canvas.getContext("2d");
        canvas.width = viewport.width;
        canvas.height = viewport.height;

        await page.render({ canvasContext: ctx, viewport }).promise;

        // Convert canvas to an image and store it
        const imgSrc = canvas.toDataURL("image/jpeg");
        extractedImages.push(imgSrc);
        testlog.innerHTML = testlog.innerHTML + "<br><br>Read page " + i;
      
    }

    return extractedImages;
}

// jQuery UI for uploading & predicting images
$(document).ready(() => {
    $("#imageUpload").on("click", async function(event) {
          $("#imageUpload").val() = null;
    });
    $("#imageUpload").on("change", async function(event) {
        alert($(this).val());
        const file = event.target.files[0];
        const url = URL.createObjectURL(file);
        classifyExtractedImages(url);
    });
        trainModel();
});
</script>
