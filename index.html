<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.min.js"></script>
<input type="file" id="imageUpload" multiple>
<div id="testlog"></div>
<script>
var testlog = document.getElementById("testlog");
// Ensure WebGPU Backend for TensorFlow.js
async function setupBackend() {
    await tf.setBackend('webgpu'); // Enables Vulkan-based GPU acceleration
    console.log(`Using backend: ${tf.getBackend()}`);
}

setupBackend();

// Load image and convert to tensor
async function loadImage(url) {
    return new Promise((resolve) => {
        const img = new Image();
        img.crossOrigin = "anonymous"; // To prevent CORS issues
        img.src = url;
        img.onload = () => resolve(img);
    });
    testlog.innerHTML = testlog.innerHTML + "<br><br>done with loadImage)";
}

// Convert image to TensorFlow.js tensor
async function processImage(img) {
    return tf.browser.fromPixels(img)
        .resizeNearestNeighbor([128, 128]) // Resize to match model input size
        .toFloat()
        .div(tf.scalar(255)) // Normalize pixel values
        .expandDims(); // Add batch dimension
}

// Define the CNN Model
const model = tf.sequential();
model.add(tf.layers.conv2d({ inputShape: [128, 128, 3], filters: 32, kernelSize: 3, activation: 'relu' }));
model.add(tf.layers.maxPooling2d({ poolSize: [2, 2] }));
model.add(tf.layers.conv2d({ filters: 64, kernelSize: 3, activation: 'relu' }));
model.add(tf.layers.maxPooling2d({ poolSize: [2, 2] }));
model.add(tf.layers.flatten());
model.add(tf.layers.dense({ units: 128, activation: 'relu' }));
model.add(tf.layers.dense({ units: 10, activation: 'softmax' })); // 10 categories (adjust as needed)

model.compile({ optimizer: tf.train.adam(), loss: 'categoricalCrossentropy', metrics: ['accuracy'] });

async function loadDataset() {
    const dataset = [];
    const categories = [
        'bagset', 'dontreadrepeat', 'finished', 'index', 'pageno', 
        'part', 'partstep', 'repeat', 'splitdecision', 'subbuild'
    ];
    const indices = [
        5, 2, 2, 4, 4, 
        26, 18, 4, 2, 6
    ];
    const baseDir = 'dataset/'; // Path relative to your GitHub-hosted environment

    for (var j = 0; j < categories.length; j++) {
        category = categories[j];
        jth = indices[j];
        for (var i = 1; i <= jth; i++){
            const imageUrl = `${baseDir}${category}/${category} ${i}.jpg`;

            try {
                const response = await fetch(imageUrl, { method: 'HEAD' });
                if (!response.ok) break; // Stop fetching when file doesn't exist

                dataset.push({
                    path: imageUrl,
                    label: categories.indexOf(category)
                });
            } catch (error) {
                break; // Stop when no more files are found
            }
    testlog.innerHTML = testlog.innerHTML + "<br><br>pushed " + category + " " + i;
        }
    }

    const imageTensors = [];
    const labels = [];

    for (const item of dataset) {
        const img = await loadImage(item.path);
        const tensor = await processImage(img);
        imageTensors.push(tensor);
        labels.push(item.label);
            testlog.innerHTML = testlog.innerHTML + "<br><br>labeled " + category + " " + i;
    }

    return {
        xs: tf.stack(imageTensors),
        ys: tf.oneHot(tf.tensor1d(labels, 'int32'), 10)
    };
}

// Train the model
async function trainModel() {
    const { xs, ys } = await loadDataset();

    await model.fit(xs, ys, {
        epochs: 20,
        batchSize: 16,
        validationSplit: 0.2,
        callbacks: tf.callbacks.earlyStopping({ patience: 3 })
    });

        testlog.innerHTML = testlog.innerHTML + "<br><br> Training Complete";
}
async function classifyExtractedImages(pdfUrl) {
    const images = await extractImagesFromPDF(pdfUrl);

    for (const imgSrc of images) {
        const img = new Image();
        img.src = imgSrc;

        img.onload = async () => {
            const tensor = await processImage(img);
            const prediction = model.predict(tensor);
            const classIndex = prediction.argMax(1).dataSync()[0];

                testlog.innerHTML = testlog.innerHTML + "<br><br>Detected category " + classIndex;
        };
    }
}
async function extractImagesFromPDF(pdfUrl) {
    const pdf = await pdfjsLib.getDocument(pdfUrl).promise;
    const numPages = pdf.numPages;
    const extractedImages = [];

    for (let i = 1; i <= numPages; i++) {
        const page = await pdf.getPage(i);
        const viewport = page.getViewport({ scale: 2.0 });

        // Render the page onto a canvas
        const canvas = document.createElement("canvas");
        const ctx = canvas.getContext("2d");
        canvas.width = viewport.width;
        canvas.height = viewport.height;

        await page.render({ canvasContext: ctx, viewport }).promise;

        // Convert canvas to an image and store it
        const imgSrc = canvas.toDataURL("image/jpeg");
        extractedImages.push(imgSrc);
    }

    return extractedImages;
}

// jQuery UI for uploading & predicting images
$(document).ready(() => {
    trainModel();
    $("#imaageUpload").on("change", async function(event) {
        const file = event.target.files[0];
        const url = URL.createObjectURL(file);
        classifyExtractedImages(url);
    });
});
</script>
